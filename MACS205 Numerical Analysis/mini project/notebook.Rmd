---
title: "Mini projet"
output: html_notebook
author : Priam Cardouat
---



Tout d'abord introduisons les données du problème :

```{r}
K <- 2.1 ## parametre k  de la loi gamma 
THETA <- 0.5 ## parametre theta de la loi gamma
densite <- function(x){dgamma(x, shape = K, scale = THETA)}
A <- 0
B <- 14
```


## Interpolation Polynomiale

### Question 1

Nous allons utiliser un interpolateur de Lagrage basé sur les différences divisées et la méthode de Horner

```{r}
dividif=function(x,y){
    ## Computes the divided differences (coefficients on the Newton basis) for
    ##  Lagrange interpolation.
    ##
    ## @title dividif: Newton's Divided differences
    ## @param x a vector containing the interpolation nodes 
    ## @param y a vector of same size as x: values of the interpolated function at
    ##          the nodes
    ## @return a vector of same size as x: the divided differences
    ##         \eqn{f_[x_0, ... x_k]} of order 'length(x) -1'.
    
    n = length(x) -1 ## n: degree of Lagrange polynomial.
    Tmat = matrix(ncol = n+1, nrow = n+1)
    Tmat[,1]  = y ## initialization of the vector of divided differences: 
    if(n ==0) {return(diag(Tmat))} 
    for (j in 2:(n+1) ) {
      Tmat[j : (n+1), j ] = (Tmat[j : (n+1), (j-1)] - Tmat[(j-1) : n, (j-1)]) / (x[j:(n+1)] - x[1 : (n+2-j)]) 
    }
    return(diag(Tmat))
}
```

```{r}
interpolDividif=function(x,y,z){
    ## Efficient Lagrange interpolation using Horner's method with  
    ## Newton basis for evaluation
    ## @param x : vector containing the interpolation nodes 
    ## @param y : vector of same size as x: values of the interpolated
    ##            function at the nodes
    ## @param z : vector of points where the  interpolating polynomial
    ##            needs to be evaluated. 
    ## @return  : vector of same size as z: the value of the
    ##            interpolating polynomial at points z.
    
  a = dividif(x,y)
  
  return(hornerNewton(a,x,z))
}
```

Cette fonction permet de se ramener du [-1,1] à [a,b]

```{r}
affineTransfo = function(a,b,u){
  return(0.5*(a+b)+0.5*(b-a)*u)
}
```

```{r}
interpolLagrange =function(n, a, b, neval, noeuds, FUN, Plot){
      ## Generic Lagrange interpolation, with equidistant or Chebyshev nodes. 
      ## @param n : the degree of the interpolating polynomial on each
      ## subinterval
      ## @param a : left end-point of the interval
      ## @param b : right end-point of the interval
      ## @param neval :number of evaluation points (a regular grid will be
      ## used on [a,b]
      ## @param nodes :string, either "equi" (default) for equidistant
      ## Lagrange interpolation (on each subinterval) or "cheby" for
      ## using Chebyshev nodes.
      ## @param FUN: the function to be interpolated 
      ## @param Plot : logical. Setting 'Plot' to TRUE produces a plot
      ## showing the graph of
      ## the true functions and its interpolation.  
      ## @return : vector of size 'neval': the values of the Lagrange
      ## polynomial on an equi-distant grid.
  
      if (noeuds == "equi"){
          x =c()
          for(i in 0:n){
            x[length(x)+1] <- a+i*(b-a)/n
          }
              }
      else if (noeuds == "cheby"){
        x =  c()
        for(k in 0:n){
          x[length(x)+1] <- cos((k+0.5)*pi/(n+1))
        }
        x=affineTransfo(a,b,x)
                      }
      else{stop("the nodes must be either 'equi' or 'cheby'") }
      z=seq(a, b, length.out=neval)
      f=interpolDividif(x , y = FUN(x) , z = z)

      
      if( Plot ){
          if (noeuds == "equi"){ methodName = " equidistant "}
          else {   methodName = " Chebyshev "}

          plot(z, sapply(z,FUN), type="l", ylim=range(c(y,f)) )
          title(main = paste("Lagrange interpolation with ",
                             toString(n), methodName,
                             " nodes", sep=""))
          lines(z,f, col = 'blue') 

          legend('topright', legend=c('function','interpolation'),
                 col = c('black','blue'), lwd=1)
          
      }
      return(f)              
  }
```

```{r}
interpolLagrange(58, A, B, 150,"equi",densite, TRUE)
```

```{r}
interpolLagrange(86,A,B,150,"cheby",densite, TRUE)
```
Le phénomène de Runge apparaît donc vers le degré d'interpolation 58 en ce qui concerne l'interpolation de la densité par avec des noeuds équidistants. Ce phénomène apparaît vers le degré 86 avec des noeuds de Tchebychev.

### Question 2

#### a)

i) Avec des noeuds équidistants, on effectue n+1 évaluation sur un intervalle pour une interpolation de lagrange de degré n. Il faut enlever parmi les noeuds ceux en "doublon", c'est-a-dire ceux sur les bords des intervalles et qui ne sont pas aux bords de l'intervalle initial. Il y a donc M(n+1)-(M-1) évaluations, c'est-a-dire Mn+1 évaluations à faire.

ii) Avec des noeuds de Tchebychev, il y aura n+1 évaluations sur chaques sous-intervalles. Comme il n'y a pas de "doublon", on devra donc faire M(n+1) évaluations.

#### b)

Commençons par le cas des noeuds équidistants :

```{r}
piecewiseInterpol=function(n,nInt,a,b,neval, nodes, FUN, Plot){
    ## @param n : the degree of the interpolating polynomial on each
    ## subinterval
    ## @param nInt :  the number of sub-intervals
    ## @param a, b : endpoints of the interval
    ## @param neval : the number of points on the interpolating grid (on
    ## each subinterval)
    ## @param nodes : string, either "equi" (default) for equidistant
    ## Lagrange interpolation (on each subinterval) or "cheby" for
    ## chebyshev nodes.
    ## @param FUN the function to be interpolated
    ## @param Plot : logical. Should the result be plotted ?
    ## @return : a matrix with 2 rows and neval * nInt -neval + 1:
    ## values of the interpolated funtion on a regular grid (first row)
    ## and the corresponding abscissas (second row).

    intEndPoints = seq(a,b,length.out = nInt+1)
    f = c()
    z = c()
    for (m in 1:nInt){
        A = intEndPoints[m]; B = intEndPoints[m+1] 
        
        fm = interpolLagrange(n, A, B, neval, nodes, FUN, Plot) 
        zm = seq(A, B, length.out=neval)
                
                if( m >= 2 && nodes == "equi"){
                    ## remove first element of zm, fm to avoid
                    ## duplicate values of the  interpolating vector
                    
                    zm = zm[zm!=zm[1]]
                    fm = fm[fm!=fm[1]]
                }
        z = c(z,zm)
        f = c(f,fm)
    }
    

    if (Plot == 1){
        if (nodes == "equi") {methodName = " equidistant "}
        else  {methodName = " Chebyshev "}
        methodName = "equidistant"
        
        plot(z, sapply(z,FUN),type="l")
        title(main = paste("Piecewise  Lagrange  interpolation with ",
                           toString(n+1), methodName, " nodes  on ",
                           toString(nInt), " Intervals", sep=""))
        lines(z,f, col='red', lwd=2)
        legend('topright', legend = c('function','interpolation'),
               lwd=c(1,2), col=c('black','red'))
    }
    return(rbind(f,z))
}

```

On doit avoir pour les points équidistants $Mn+1 \leq 150$ et comme pour n fixé on cherche à prendre le M le plus grand possible, on va prendre $M = \lfloor \frac{149}{n} \rfloor$.

```{r}
findBestPiecewiseEqui=function(a,b,neval,FUN){
  list_n = c()
  list_M = c()
  erreur=c()
  for(n in 1:149){
    M = 149%/%n
    f = piecewiseInterpol(n,M,a,b,(neval-1+M)%/%M,"equi",FUN,FALSE)
    erreur[length(erreur)+1]=max(abs(FUN(f[2,])-f[1,]))
    list_n = c(list_n,n)
    list_M = c(list_M,M)
  }
  Mn = rbind(list_M,list_n)
  ind = which.min(erreur)
  n = Mn[2,]
  plot(n, erreur,type="l")
        title(main = paste("Error with different n"))
  return(c(Mn[,ind], min(erreur)))
}
```

```{r}
findBestPiecewiseEqui(A,B,2000,densite)
```
Nous allons appliquer le même principe pour des noeuds de Chebychev :

```{r}
findBestPiecewiseCheby=function(a,b,neval,FUN){
  list_n = c()
  list_M = c()
  erreur=c()
  for(n in 1:149){
    M = 149%/%n
    f = piecewiseInterpol(n,M,a,b,(neval-1+M)%/%M,"cheby",FUN,FALSE)
    erreur[length(erreur)+1]=max(abs(FUN(f[2,])-f[1,]))
    list_n = c(list_n,n)
    list_M = c(list_M,M)
  }
  Mn = rbind(list_M,list_n)
  ind = which.min(erreur)
  n = Mn[2,]
  plot(n, erreur,type="l")
        title(main = paste("Error with different n"))
  return(c(Mn[,ind], min(erreur)))
}
```


```{r}
findBestPiecewiseCheby(A,B,2000,densite)
```

Nous pouvons donc constater que l'erreur optimale est meilleure avec des noeuds de Tchebychev. Par ailleurs, nous constatons que les (M,n) obtenus sont un peu différents ((3,49) avec des noeuds equidistants et (2,68) pour des noeuds de Tchebychev, sans être toutefois dramatiquement différents).Enfin, les deux courbes de l'erreur en fonction de n sont similaires, avec des erreurs faibles jusqu'à environ n=140 avant que celle-ci n'explose. Nous pourrions donc conclure qu'il est préférable d'utiliser des noeuds de Tchebychev.


### Méthodes de quadrature

```{r}
a <- 0
b <- 3.5
```


#### Méthode de Simpson

**Question 1**

a) Avec la méthode de quadrature composite de Cavaleri-Simpson, on effectue 3 évaluations par sous-intervalle, et si on retire les "doublons", nous réalisons au final $3M-M+1$ évaluations. Puisqu'on a un budget de 81 évaluations, il faut donc prendre $M=40$ au maximum.

b) La méthode de quadrature composite de Cavaleri-Simpson est une méthode de Newton-Cotes de rang 2, et donc d'ordre 3 et notons $h=\frac{b-a}{M}$ le pas. D'après la proposition 3.5.1, il existe $\theta_{M} \in [a,b]$ tel que l'erreur est donnée par $EI_{M}^{(a,b)}(\phi_{\theta_{M} ,k}) = K \phi^{(4)}(\theta_{M})(b-a)h^{4}$ avec K une constante strictement positive indépendante de (a,b).
Aussi, nous pouvons donc écrire :
$$\frac{EI_{2M}^{(a,b)}(\phi_{\theta_{M} ,k})}{EI_{M}^{(a,b)}(\phi_{\theta_{M} ,k})} = \frac{\phi^{(4)}(\theta_{2M})(h/2)^{4}}{\phi^{(4)}(\theta_{M})h^{4}} = \frac{1}{16} \frac{\phi^{(4)}(\theta_{2M})}{\phi^{(4)}(\theta_{M})}$$
On suppose que $\phi^{(4)}(\theta_{M})$ ne dépend pas de $M$ (car il est réaliste que $\theta_{M}$ ne dépende pas de $M$). Ainsi :

$$\frac{EI_{2M}^{(a,b)}(\phi_{\theta_{M} ,k})}{EI_{M}^{(a,b)}(\phi_{\theta_{M} ,k})} \approx \frac{1}{16}$$

Ainsi, $\frac{\hat{I}_{2M}^{simp}-I}{\hat{I}_{M}^{simp}-I} \approx \frac{1}{16}$ donc $\hat{I}_{2M}^{simp}-I=\frac{1}{16}\hat{I}_{M}^{simp} - \frac{1}{16}I = \hat{I}_{M}^{simp} - \frac{15}{16}-\frac{1}{16}I$.

Donc $\hat{I}_{2M}^{simp} - \hat{I}_{M}^{simp} \approx -\frac{15}{16}EI_{M}^{(a,b)}$. Par conséquent, comme $EI_{2M}^{(a,b)}(\phi_{\theta_{M} ,k}) \approx \frac{EI_{M}^{(a,b)}(\phi_{\theta_{M} ,k})}{16}$, on a :

$$EI_{2M}^{(a,b)}(\phi_{\theta_{M} ,k}) \approx \frac{\hat{I}_{M}^{simp}-\hat{I}_{2M}^{simp}}{15}$$
```{r}
## Méthode des trapèzes
trapezeInt =function(FUN,a,b,M){
  ##' TRAPEZOIDAL INTEGRATION RULE (COMPOSITE)
  ##' @param FUN : the function to be integrated
  ##' @param a, b : interval end points 
  ##' @param M : number of intervals (each of size (b-a)/M)
  ##' @return: the value of the composite trapezoidal quadrature. 
  x = seq(a,b, length.out= M+1)
  y = sapply(x, FUN)
  h = (b-a)/M 
  w = rep(1,M+1)
  w[1] <- 0.5
  w[M+1] <- 0.5
  q = h*(sum(y*w))
    
  return(q)
}
```


```{r}
## Division du pas des trapèzes par 2
refineTrapeze=function(FUN,a,b,M,q){
  ##' refinement of the subdivision step: incremental method
  ##' @param FUN : the function to be integrated
  ##' @param a, b : interval end points 
  ##' @param M : initial number of intervals (each of size (b-a)/M)
  ##'  having been used to compute q
  ##' @param  q : the value of the trapezoidal  quadrature method
  ##'  of stepsize (b-a)/M
  ##' @return : the value of the quadrature for a stepsize h' = h/2
  h = (b-a)/M
  x = seq(a+h*0.5, b-h*0.5, length.out= M) ## complete here : 
    ##  x : a vector of size M :
    ##     the additional abscissas where 'fun' must be evaluated.
  y = sapply(x, FUN)
  Q = 0.5*q+0.5*h*sum(y)##  complete here : a function of y, h and q. 
    return(Q)
}
```


```{r}
## Méthode de Simpson
simpsonInt = function(FUN,a,b,M){
  ##' Simpson integration via trapeze rule
  ##' uses the fact that 
  ##' simpson(h) = 4/3(trapeze(h/2) - 1/4 trapeze(h))
  qtrapeze = trapezeInt(FUN,a,b,M)
  qrefined = refineTrapeze(FUN,a,b,M,qtrapeze)
  q =  (4/3)*(qrefined-(1/4)*qtrapeze) 
  return(q)
}
```


```{r}
## Evaluation de l'erreur a posteriori
evalErrSimpson=function(FUN,a,b,M){
  ## Computes an approximation E of the error 
  ## for the composite Simpson rule of step h=(b-a)/(2M). 
  ##This requires computing I_M and I_{2M}. 
  ##The value  q = I_{2M} is also returned. 
  qth = trapezeInt(FUN,a,b,M)   ## M +1 evaluations
  qth2 = refineTrapeze ( FUN,a,b,M,qth )  ## M evaluations
  qth4 = refineTrapeze ( FUN,a,b,2*M,qth2 )   ## 2M evaluations
  simps_h =   4/3*(qth2 - 1/4* qth ) 
  simps_h2 =  4/3*(qth4 - 1/4* qth2 )
  q = simps_h2  
  E = (simps_h-q)/15 
  return(c(E,simps_h))
}
```

```{r}
evalErrSimpson(densite,a,b,40/2)
```
L'erreur a posteriori avec un budget de $M=40$ sous-intervalles est de 8.422013e-06 et on a $\hat{I}_{M}^{simp} = 9.915757e-01$.


c) Calculons l'erreur relative :

```{r}
erreurRelative=function(a,b,M){
  temp = evalErrSimpson(densite,a,b,M/2)
  err1 = temp[1]
  err2 = temp[2]-pgamma(b,shape=K,scale=THETA)
  return(abs(err1-err2)/err2)
}
```

```{r}
erreurRelative(a,b,40)
```

Nous pouvons donc constater que l'erreur relative proche de 1, ce qui permet de dire que l'erreur a posteriori est assez fidèle à l'erreur réelle.


#### Méthode de Romberg

##### Question 1


```{r}
## Méthode de Romberg
romberg =function(FUN,n,a,b,M){## methode de Romberg avec n etapes
  ## appliquee sur la fonction FUN sur l'intervalle (a,b), avec un
  ## pas initial h = (b-a)/M
  h= (b-a)/M 
  A = matrix(ncol = n+1, nrow = n+1)
  A[1,1] = trapezeInt(FUN,a,b,M);
  Mc = M
  ## initialisation des differences divisees
  for( i in 2:(n+1)){
    A[i,1] = refineTrapeze( FUN,a,b, Mc, q= A[i-1,1])
    Mc = 2*Mc 
  }
  delta = 1/4;
  lx = log(delta)*(0:n)
  x = exp(lx);
  for (j in 2:(n+1)){
    A[j : (n+1), j ] = (A[j : (n+1), (j-1)] - (x[j:(n+1)])*A[(j-1) : n, (j-1)]) / (1 - x[j:(n+1)])
  }
  return(diag(A))
}
```


```{r}
estRomberg = romberg(densite,20,a,b,2)
lx = log(t)  +  log(delta) *(0:20)
x = exp(lx)
plot(x, estRomberg,col='blue',type='l')
```
Nous pouvons constater que la valeur en 0 est proche de 1, ce qui correspond à peu près à la valeur de l'intégrale recherchée.

##### Question 2


```{r}
M = 2
n = 20
B = rep(0,n+1)
B[1] = trapezeInt(densite,a,b,M) 
Mc = M
for( i in  2:(n+1)){
  B[i] = refineTrapeze( densite,a,b, Mc, B[i-1])
  Mc = 2* Mc 
}
LerrRich = log(abs(estRomberg - pgamma(b,shape=K,scale=THETA))) ;  
LerrNaive = log(abs(B - pgamma(b,shape=K,scale=THETA)));
plot((0:n), LerrNaive,col='blue',type='l')
lines( (0:n), LerrRich, col='red')
grid()
legend('topright', legend=c('log-erreur naive', 'log-erreur Romberg'),
       col=c('blue', 'red'), lwd=2)
```

On peut donc constater que les erreurs sont quasi identiques et donc que les deux estimateurs conviennent (même si l'estimateur de Romberg est légèrement préférable pour de faibles valeurs de n).

